<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CB Survey</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <h1>Compositional Behavior (CB) Survey</h1>

        <p>These are the survey questions (although not shown in the original survey presentation) from Toward Compositional Behavior in Neural Models: A Survey of Current Views (McCurdy et al., EMNLP 2024). 
            Take it yourself and see which cluster aligns with your views!</p>
        
        <form id="surveyForm">
            <h2>Defining CB</h2>
            <div class="question" id="S0">
                <p>       <b>(CB)</b> When a model receives an input <i>I</i> that humans conceive as composed of component parts, if the model produces correct outputs for those parts (in isolation or in other combinations), then it will also produce a correct output for  <i>I</i>.</p>
                <p>       <b>S0</b>. (CB) is a satisfactory working definition of compositional behavior, an important aspect of compositional generalization. </p>
                <select name="S0">
                    <option value="" disabled selected>Select:</option>
                    <option value="-5.5">Strongly Disagree</option>
                    <option value="-4.5">Disagree</option>
                    <option value="-3.5">Somewhat Disagree</option>
                    <option value="3.5">Somewhat Agree</option>
                    <option value="4.5">Agree</option>
                    <option value="5.5">Strongly Agree</option>
                </select>
            </div>
            
            <h2>Evaluating CB</h2>
            <div class="question" id="S1">
                <p>       <b>S1</b>. Current methods for analyzing the behavior of neural models are sufficient to assess whether a model is capable of compositional behavior (CB). For example, consider methods used to assess performance on datasets designed to probe specific aspects of compositional generalization, such as SCAN, COGs, CFQ, PCFG, Colors, etc. </p>
                <select name="S1">
                    <option value="-5.5">Strongly Disagree</option>
                    <option value="-4.5">Disagree</option>
                    <option value="-3.5">Somewhat Disagree</option>
                    <option value="3.5">Somewhat Agree</option>
                    <option value="4.5">Agree</option>
                    <option value="5.5">Strongly Agree</option>
                </select>
            </div>
            
            <div class="question" id="S2">
                <p>       <b>S2</b>. Current methods for analyzing the representations within neural models are sufficient: if a model is capable of compositional behavior (CB), these analysis methods can identify the model-internal mechanisms 
            supporting this behavior.
            For example, consider diagnostic probing, visualization, learning interpretable approximations of the representation space, etc.</p>
                <select name="S2">
                    <option value="-5.5">Strongly Disagree</option>
                    <option value="-4.5">Disagree</option>
                    <option value="-3.5">Somewhat Disagree</option>
                    <option value="3.5">Somewhat Agree</option>
                    <option value="4.5">Agree</option>
                    <option value="5.5">Strongly Agree</option>
                </select>
            </div>
            
            <div class="question" id="S3">
                <p>       <b>S3</b>. Current methods for analyzing the processing within neural models are sufficient: if a model is capable of compositional behavior (CB), these analysis methods can identify the model-internal mechanisms supporting this behavior.
            For example, consider analysis of circuits / induction heads, causal interventions such as ablation, etc. </p>
                <select name="S3">
                    <option value="-5.5">Strongly Disagree</option>
                    <option value="-4.5">Disagree</option>
                    <option value="-3.5">Somewhat Disagree</option>
                    <option value="3.5">Somewhat Agree</option>
                    <option value="4.5">Agree</option>
                    <option value="5.5">Strongly Agree</option>
                </select>
            </div>
                        
            <div class="question" id="S4">
                <p>       <b>S4</b> Interpretable representations are necessary: we cannot evaluate whether a model is capable of compositional behavior (CB) unless we can identify human-interpretable parts within its representational structure. </p>
                <select name="S4">
                    <option value="-5.5">Strongly Disagree</option>
                    <option value="-4.5">Disagree</option>
                    <option value="-3.5">Somewhat Disagree</option>
                    <option value="3.5">Somewhat Agree</option>
                    <option value="4.5">Agree</option>
                    <option value="5.5">Strongly Agree</option>
                </select>
            </div>

            <div class="question" id="S5">
                <p>       <b>S5</b>. Interpretable processing is necessary: we cannot evaluate whether a model is capable of compositional behavior (CB) unless we can identify human-interpretable parts within its representational structure, and establish that the model uses these parts as expected during processing.
            That is to say, if we observe in compositional behavior that certain parts stand in particular relations to one another, we can confirm that those parts interact in similar — ideally isomorphic — ways during the procedure carried out by the model, at some level of description. For example, consider the conceptual roles discussed by Piantadosi and Hill (2022). </p>
                <select name="S5">
                    <option value="-5.5">Strongly Disagree</option>
                    <option value="-4.5">Disagree</option>
                    <option value="-3.5">Somewhat Disagree</option>
                    <option value="3.5">Somewhat Agree</option>
                    <option value="4.5">Agree</option>
                    <option value="5.5">Strongly Agree</option>
                </select>
            </div>

            <div class="question" id="S6">
                <p>       <b>S6</b>. External grounding is necessary: we cannot evaluate whether a model is capable of compositional behavior (CB) unless we can identify human-interpretable parts within its representational structure, and establish that these parts are grounded with respect to some model-external structure in the world. </p>
                <select name="S6">
                    <option value="-5.5">Strongly Disagree</option>
                    <option value="-4.5">Disagree</option>
                    <option value="-3.5">Somewhat Disagree</option>
                    <option value="3.5">Somewhat Agree</option>
                    <option value="4.5">Agree</option>
                    <option value="5.5">Strongly Agree</option>
                </select>
            </div>

            <h2>Achieving CB</h2>

            <div class="question" id="S7">
                <p>       <b>S7</b>. Current neural models show a sufficient degree of compositional behavior (CB); we don’t need to assign high priority to further research on this topic. </p>
                <select name="S7">
                    <option value="-5.5">Strongly Disagree</option>
                    <option value="-4.5">Disagree</option>
                    <option value="-3.5">Somewhat Disagree</option>
                    <option value="3.5">Somewhat Agree</option>
                    <option value="4.5">Agree</option>
                    <option value="5.5">Strongly Agree</option>
                </select>
            </div>

            <div class="question" id="S8">
                <p>       <b>S8</b>. Current neural models do not show a sufficient degree of compositional behavior (CB), but this issue will likely be resolved as a byproduct of increasing model capacity (i.e.~larger models and/or larger datasets).
            In other words, scale will solve this problem, and we don't need additional interventions to improve compositional behavior. </p>
                <select name="S8">
                    <option value="-5.5">Strongly Disagree</option>
                    <option value="-4.5">Disagree</option>
                    <option value="-3.5">Somewhat Disagree</option>
                    <option value="3.5">Somewhat Agree</option>
                    <option value="4.5">Agree</option>
                    <option value="5.5">Strongly Agree</option>
                </select>
            </div>

            <div class="question" id="S9">
                <p>       <b>S9</b>.  Current neural models do not show a sufficient degree of compositional behavior (CB), and some intervention is required, but model-external interventions — as opposed to the model-internal interventions considered in the next claim — are likely to satisfactorily resolve this problem. Examples of model-external interventions include prompt engineering; strategic manipulation or augmentation of training data; and auxiliary tasks during training, pre-training, or fine-tuning. </p>
                <select name="S9">
                    <option value="-5.5">Strongly Disagree</option>
                    <option value="-4.5">Disagree</option>
                    <option value="-3.5">Somewhat Disagree</option>
                    <option value="3.5">Somewhat Agree</option>
                    <option value="4.5">Agree</option>
                    <option value="5.5">Strongly Agree</option>
                </select>
            </div>

            <div class="question" id="S10">
                <p>       <b>S10</b>. Current neural models do not show a sufficient degree of compositional behavior (CB), and model-external interventions are unlikely to resolve this issue.
            Model-internal interventions or novel architectures, focused on model representations/processing/learning, will be necessary to solve the problem. </p>
                <select name="S10">
                    <option value="-5.5">Strongly Disagree</option>
                    <option value="-4.5">Disagree</option>
                    <option value="-3.5">Somewhat Disagree</option>
                    <option value="3.5">Somewhat Agree</option>
                    <option value="4.5">Agree</option>
                    <option value="5.5">Strongly Agree</option>
                </select>
            </div>

            <div class="question" id="S11">
                <p>       <b>S11</b>. Current neural models do not show a sufficient degree of compositional behavior (CB), and model-internal interventions or novel architectures that incorporate explicit discrete symbolic computation (e.g., program synthesis) will be necessary to solve the problem. </p>
                <select name="S11">
                    <option value="-5.5">Strongly Disagree</option>
                    <option value="-4.5">Disagree</option>
                    <option value="-3.5">Somewhat Disagree</option>
                    <option value="3.5">Somewhat Agree</option>
                    <option value="4.5">Agree</option>
                    <option value="5.5">Strongly Agree</option>
                </select>
            </div>            
            
            <button type="button" onclick="calculateCluster()">Submit</button>
        </form>
        <div id="result"></div>
    </div>
    <script src="script.js"></script>
</body>
</html>
